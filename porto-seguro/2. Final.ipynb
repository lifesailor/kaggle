{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'AppleGothic'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법론\n",
    "\n",
    "1. Cross Validation Fold = 10\n",
    "2. Feature Selection\n",
    "    1) delete_features = ['ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n",
    "    \n",
    "    \n",
    "3. Feature Engineering\n",
    "    1) categorical relabeling: 10\n",
    "\n",
    "4. 결측치는 모델에게 맡김\n",
    "\n",
    "5. Model\n",
    "    1) LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/base-workspace/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from gini import gini, gini_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 데이터 전처리\n",
    "folder_loc = '/Users/lifesailor/.kaggle/porto-seguro/'\n",
    "\n",
    "train = pd.read_csv(folder_loc + 'train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "\n",
    "test = pd.read_csv(folder_loc + 'test.csv')\n",
    "test_id = test['id']\n",
    "del test['id']\n",
    "del train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuouse, ordinal variables:  ['ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02']\n",
      "binary variables:  ['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin']\n",
      "catgorical variables:  ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat']\n"
     ]
    }
   ],
   "source": [
    "bin_vars = []\n",
    "cat_vars = []\n",
    "con_ord_vars = []\n",
    "\n",
    "for col in train.columns[2:]:\n",
    "    if 'cat' in col:\n",
    "        cat_vars.append(col)\n",
    "    elif 'bin' in col:\n",
    "        bin_vars.append(col)\n",
    "    else:\n",
    "        con_ord_vars.append(col)\n",
    "\n",
    "print(\"continuouse, ordinal variables: \", con_ord_vars[:5])\n",
    "print(\"binary variables: \", bin_vars[:5])\n",
    "print(\"catgorical variables: \", cat_vars[:5])\n",
    "\n",
    "for col in cat_vars:\n",
    "    train[col] = train[col].astype('O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fill = train.copy()\n",
    "test_fill = test.copy()\n",
    "\n",
    "features = []\n",
    "features += con_ord_vars\n",
    "features += bin_vars[:-6]\n",
    "features = list(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/base-workspace/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_fill_cat = train[cat_vars].astype('O')\n",
    "test_fill_cat = test[cat_vars].astype('O')\n",
    "\n",
    "train_test = pd.concat([train_fill, test_fill], axis=0)\n",
    "\n",
    "### 2. categorical relabeling\n",
    "cat_features = {}\n",
    "\n",
    "for col in train[cat_vars].columns:\n",
    "    cat_features[col] = len(train_fill_cat[col].unique())\n",
    "\n",
    "new_category_col = {}\n",
    "for col in cat_vars:\n",
    "    if len(train_fill[col].unique()) <= 7:\n",
    "        new_category_col[col] = train[col].unique()\n",
    "        continue\n",
    "    \n",
    "    target_by_category = train.groupby(col)['target'].mean().sort_values(ascending=False)\n",
    "    unique_category_length = len(target_by_category) / 7\n",
    "    \n",
    "    \n",
    "    new_category_col[col] = [target_by_category[int(i * unique_category_length):\n",
    "                                                int((i+1) * unique_category_length)].index.values\n",
    "                                                for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/base-workspace/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((595212, 124), (892816, 123))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, category in new_category_col.items():\n",
    "    length = len(category)\n",
    "    \n",
    "    for i in range(length):\n",
    "        new_column = key + '_new_' + str(i)\n",
    "        train_fill[new_column] = 0\n",
    "        \n",
    "        if type(category) is list:\n",
    "            train_fill.loc[train_fill[key].isin(category[i]), new_column] = 1\n",
    "            test_fill.loc[test_fill[key].isin(category[i]), new_column] = 1\n",
    "        else:\n",
    "            train_fill.loc[train_fill[key] == category[i], new_column] = 1\n",
    "            test_fill.loc[test_fill[key] == category[i], new_column] = 1\n",
    "\n",
    "cat_features_lst = [feature for feature in train_fill.columns if 'new' in feature] \n",
    "features += cat_features_lst\n",
    "\n",
    "train_test = pd.concat([train_fill, test_fill], axis=0)\n",
    "train_fill.shape, test_fill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fill.drop(columns='target', axis=1, inplace=True)\n",
    "train_fill.shape, test_fill.shape\n",
    "\n",
    "train_new = train_fill.astype(float).copy()\n",
    "test_new = test_fill.astype(float).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from gini import gini, gini_normalized\n",
    "\n",
    "# LightGBM 모델의 설정값이다.\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"binary\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": 0.02,\n",
    "          \"num_leaves\": 15,\n",
    "          \"max_bin\": 256,\n",
    "          \"feature_fraction\": 0.6,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"is_unbalance\": False,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9,\n",
    "          \"seed\": 2018\n",
    "}\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', gini_normalized(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152996\tvalid_0's gini: 0.264874\n",
      "[200]\tvalid_0's binary_logloss: 0.152459\tvalid_0's gini: 0.272241\n",
      "[300]\tvalid_0's binary_logloss: 0.152285\tvalid_0's gini: 0.276157\n",
      "[400]\tvalid_0's binary_logloss: 0.152246\tvalid_0's gini: 0.277057\n",
      "[500]\tvalid_0's binary_logloss: 0.152217\tvalid_0's gini: 0.278038\n",
      "[600]\tvalid_0's binary_logloss: 0.152194\tvalid_0's gini: 0.278638\n",
      "[700]\tvalid_0's binary_logloss: 0.152186\tvalid_0's gini: 0.27874\n",
      "[800]\tvalid_0's binary_logloss: 0.152187\tvalid_0's gini: 0.278856\n",
      "Early stopping, best iteration is:\n",
      "[752]\tvalid_0's binary_logloss: 0.152171\tvalid_0's gini: 0.27931\n",
      "0.27931040135041235\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152842\tvalid_0's gini: 0.263249\n",
      "[200]\tvalid_0's binary_logloss: 0.15218\tvalid_0's gini: 0.274236\n",
      "[300]\tvalid_0's binary_logloss: 0.151936\tvalid_0's gini: 0.28046\n",
      "[400]\tvalid_0's binary_logloss: 0.151855\tvalid_0's gini: 0.282875\n",
      "[500]\tvalid_0's binary_logloss: 0.151793\tvalid_0's gini: 0.284663\n",
      "[600]\tvalid_0's binary_logloss: 0.151759\tvalid_0's gini: 0.285637\n",
      "[700]\tvalid_0's binary_logloss: 0.151755\tvalid_0's gini: 0.285797\n",
      "[800]\tvalid_0's binary_logloss: 0.151757\tvalid_0's gini: 0.285521\n",
      "Early stopping, best iteration is:\n",
      "[702]\tvalid_0's binary_logloss: 0.151753\tvalid_0's gini: 0.285858\n",
      "0.28585780880686357\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152422\tvalid_0's gini: 0.273077\n",
      "[200]\tvalid_0's binary_logloss: 0.151777\tvalid_0's gini: 0.27988\n",
      "[300]\tvalid_0's binary_logloss: 0.151561\tvalid_0's gini: 0.284321\n",
      "[400]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.28635\n",
      "[500]\tvalid_0's binary_logloss: 0.151429\tvalid_0's gini: 0.2877\n",
      "[600]\tvalid_0's binary_logloss: 0.151413\tvalid_0's gini: 0.28832\n",
      "[700]\tvalid_0's binary_logloss: 0.151401\tvalid_0's gini: 0.288478\n",
      "[800]\tvalid_0's binary_logloss: 0.151385\tvalid_0's gini: 0.2892\n",
      "[900]\tvalid_0's binary_logloss: 0.151367\tvalid_0's gini: 0.289874\n",
      "[1000]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.289806\n",
      "Early stopping, best iteration is:\n",
      "[933]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.290172\n",
      "0.29017164918334387\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152848\tvalid_0's gini: 0.26113\n",
      "[200]\tvalid_0's binary_logloss: 0.152205\tvalid_0's gini: 0.273269\n",
      "[300]\tvalid_0's binary_logloss: 0.151943\tvalid_0's gini: 0.280616\n",
      "[400]\tvalid_0's binary_logloss: 0.151865\tvalid_0's gini: 0.282954\n",
      "[500]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.284577\n",
      "[600]\tvalid_0's binary_logloss: 0.151792\tvalid_0's gini: 0.285611\n",
      "[700]\tvalid_0's binary_logloss: 0.151779\tvalid_0's gini: 0.286204\n",
      "[800]\tvalid_0's binary_logloss: 0.151783\tvalid_0's gini: 0.285819\n",
      "Early stopping, best iteration is:\n",
      "[763]\tvalid_0's binary_logloss: 0.151771\tvalid_0's gini: 0.286451\n",
      "0.28645063904818036\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.15247\tvalid_0's gini: 0.273356\n",
      "[200]\tvalid_0's binary_logloss: 0.151747\tvalid_0's gini: 0.283376\n",
      "[300]\tvalid_0's binary_logloss: 0.151485\tvalid_0's gini: 0.288589\n",
      "[400]\tvalid_0's binary_logloss: 0.15141\tvalid_0's gini: 0.289892\n",
      "[500]\tvalid_0's binary_logloss: 0.151378\tvalid_0's gini: 0.290539\n",
      "[600]\tvalid_0's binary_logloss: 0.151375\tvalid_0's gini: 0.290465\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.290572\n",
      "0.2905718206449686\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.15257\tvalid_0's gini: 0.276449\n",
      "[200]\tvalid_0's binary_logloss: 0.151922\tvalid_0's gini: 0.28565\n",
      "[300]\tvalid_0's binary_logloss: 0.151707\tvalid_0's gini: 0.29122\n",
      "[400]\tvalid_0's binary_logloss: 0.151616\tvalid_0's gini: 0.294346\n",
      "[500]\tvalid_0's binary_logloss: 0.151578\tvalid_0's gini: 0.295974\n",
      "[600]\tvalid_0's binary_logloss: 0.151543\tvalid_0's gini: 0.2969\n",
      "Early stopping, best iteration is:\n",
      "[591]\tvalid_0's binary_logloss: 0.15154\tvalid_0's gini: 0.297003\n",
      "0.2970029025256726\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152269\tvalid_0's gini: 0.288779\n",
      "[200]\tvalid_0's binary_logloss: 0.15153\tvalid_0's gini: 0.296894\n",
      "[300]\tvalid_0's binary_logloss: 0.151345\tvalid_0's gini: 0.298967\n",
      "[400]\tvalid_0's binary_logloss: 0.151308\tvalid_0's gini: 0.299097\n",
      "[500]\tvalid_0's binary_logloss: 0.151298\tvalid_0's gini: 0.299005\n",
      "Early stopping, best iteration is:\n",
      "[437]\tvalid_0's binary_logloss: 0.151292\tvalid_0's gini: 0.299363\n",
      "0.29936256721331234\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152643\tvalid_0's gini: 0.270197\n",
      "[200]\tvalid_0's binary_logloss: 0.151889\tvalid_0's gini: 0.282853\n",
      "[300]\tvalid_0's binary_logloss: 0.151615\tvalid_0's gini: 0.2887\n",
      "[400]\tvalid_0's binary_logloss: 0.151533\tvalid_0's gini: 0.290345\n",
      "[500]\tvalid_0's binary_logloss: 0.151493\tvalid_0's gini: 0.291119\n",
      "[600]\tvalid_0's binary_logloss: 0.151474\tvalid_0's gini: 0.291399\n",
      "[700]\tvalid_0's binary_logloss: 0.151455\tvalid_0's gini: 0.291913\n",
      "[800]\tvalid_0's binary_logloss: 0.15144\tvalid_0's gini: 0.292642\n",
      "[900]\tvalid_0's binary_logloss: 0.151434\tvalid_0's gini: 0.292908\n",
      "[1000]\tvalid_0's binary_logloss: 0.151457\tvalid_0's gini: 0.292415\n",
      "Early stopping, best iteration is:\n",
      "[910]\tvalid_0's binary_logloss: 0.151434\tvalid_0's gini: 0.292979\n",
      "0.2929794288083118\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.152783\tvalid_0's gini: 0.272756\n",
      "[200]\tvalid_0's binary_logloss: 0.152118\tvalid_0's gini: 0.283532\n",
      "[300]\tvalid_0's binary_logloss: 0.151899\tvalid_0's gini: 0.288148\n",
      "[400]\tvalid_0's binary_logloss: 0.151812\tvalid_0's gini: 0.290213\n",
      "[500]\tvalid_0's binary_logloss: 0.151776\tvalid_0's gini: 0.291381\n",
      "[600]\tvalid_0's binary_logloss: 0.151753\tvalid_0's gini: 0.292123\n",
      "[700]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.291863\n",
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's binary_logloss: 0.151743\tvalid_0's gini: 0.292435\n",
      "0.2924351794554219\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.153287\tvalid_0's gini: 0.239927\n",
      "[200]\tvalid_0's binary_logloss: 0.152865\tvalid_0's gini: 0.24827\n",
      "[300]\tvalid_0's binary_logloss: 0.152726\tvalid_0's gini: 0.253076\n",
      "[400]\tvalid_0's binary_logloss: 0.15265\tvalid_0's gini: 0.25565\n",
      "[500]\tvalid_0's binary_logloss: 0.152613\tvalid_0's gini: 0.256891\n",
      "[600]\tvalid_0's binary_logloss: 0.152601\tvalid_0's gini: 0.257355\n",
      "[700]\tvalid_0's binary_logloss: 0.152603\tvalid_0's gini: 0.257577\n",
      "Early stopping, best iteration is:\n",
      "[642]\tvalid_0's binary_logloss: 0.152595\tvalid_0's gini: 0.257736\n",
      "0.2577364565981507\n"
     ]
    }
   ],
   "source": [
    "NFOLDS = 10\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=2018)\n",
    "kf = kfold.split(train_new, train_label)\n",
    "\n",
    "cv_train = np.zeros(len(train_label))\n",
    "cv_pred = np.zeros(len(test_id))    \n",
    "best_trees = []\n",
    "fold_scores = []\n",
    "\n",
    "for i, (train_fold, validate) in enumerate(kf):\n",
    "    # 훈련/검증 데이터를 분리한다\n",
    "    X_train, X_validate, label_train, label_validate = train_new.iloc[train_fold, :], train_new.iloc[validate, :], train_label[train_fold], train_label[validate]\n",
    "    dtrain = lgbm.Dataset(X_train, label_train)\n",
    "    dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "    \n",
    "    # 훈련 데이터를 학습하고, evalerror() 함수를 통해 검증 데이터에 대한 정규화 Gini 계수 점수를 기준으로 최적의 트리 개수를 찾는다.\n",
    "    bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, feval=evalerror, verbose_eval=100, early_stopping_rounds=100)\n",
    "    best_trees.append(bst.best_iteration)\n",
    "    \n",
    "    # 테스트 데이터에 대한 예측값을 cv_pred에 더한다.\n",
    "    cv_pred += bst.predict(test_new, num_iteration=bst.best_iteration)\n",
    "    cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "    # 검증 데이터에 대한 평가 점수를 출력한다.\n",
    "    score = gini_normalized(label_validate, cv_train[validate])\n",
    "    print(score)\n",
    "    fold_scores.append(score)\n",
    "\n",
    "cv_pred /= NFOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv score:\n",
      "0.2870140119919881\n",
      "[0.27931040135041235, 0.28585780880686357, 0.29017164918334387, 0.28645063904818036, 0.2905718206449686, 0.2970029025256726, 0.29936256721331234, 0.2929794288083118, 0.2924351794554219, 0.2577364565981507]\n",
      "[752, 702, 933, 763, 508, 591, 437, 910, 615, 642] 685.3\n"
     ]
    }
   ],
   "source": [
    "# 시드값별로 교차 검증 점수를 출력한다.\n",
    "print(\"cv score:\")\n",
    "print(gini_normalized(train_label, cv_train))\n",
    "print(fold_scores)\n",
    "print(best_trees, np.mean(best_trees))\n",
    "\n",
    "test_submission = pd.DataFrame({'id': test_id, 'target': cv_pred})\n",
    "test_submission.to_csv('../porto-seguro/final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
