{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle: https://www.kaggle.com/mmueller/stacking-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "ID = 'id'\n",
    "TARGET = 'loss'\n",
    "NFOLDS = 4\n",
    "SEED = 0\n",
    "NROWS = None\n",
    "DATA_DIR = \"../input\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"{0}/train.csv\".format(DATA_DIR)\n",
    "TEST_FILE = \"{0}/test.csv\".format(DATA_DIR)\n",
    "SUBMISSION_FILE = \"{0}/sample_submission.csv\".format(DATA_DIR)\n",
    "\n",
    "train = pd.read_csv(TRAIN_FILE, nrows=NROWS)\n",
    "test = pd.read_csv(TEST_FILE, nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 130) (125546, 130)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[TARGET].ravel()\n",
    "\n",
    "train.drop([ID, TARGET], axis=1, inplace=True)\n",
    "test.drop([ID], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 130),(125546, 130)\n"
     ]
    }
   ],
   "source": [
    "print(\"{},{}\".format(train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "# concat train and test\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10    ...     \\\n",
      "0     0     1     0     1     0     0     0     0     1      0    ...      \n",
      "1     0     1     0     0     0     0     0     0     1      1    ...      \n",
      "2     0     1     0     0     1     0     0     0     1      1    ...      \n",
      "3     1     1     0     1     0     0     0     0     1      0    ...      \n",
      "4     0     1     0     1     0     0     0     0     1      1    ...      \n",
      "\n",
      "      cont5     cont6     cont7    cont8    cont9   cont10    cont11  \\\n",
      "0  0.310061  0.718367  0.335060  0.30260  0.67135  0.83510  0.569745   \n",
      "1  0.885834  0.438917  0.436585  0.60087  0.35127  0.43919  0.338312   \n",
      "2  0.397069  0.289648  0.315545  0.27320  0.26076  0.32446  0.381398   \n",
      "3  0.422268  0.440945  0.391128  0.31796  0.32128  0.44467  0.327915   \n",
      "4  0.704268  0.178193  0.247408  0.24564  0.22089  0.21230  0.204687   \n",
      "\n",
      "     cont12    cont13    cont14  \n",
      "0  0.594646  0.822493  0.714843  \n",
      "1  0.366307  0.611431  0.304496  \n",
      "2  0.373424  0.195709  0.774425  \n",
      "3  0.321570  0.605077  0.602642  \n",
      "4  0.202213  0.246011  0.432606  \n",
      "\n",
      "[5 rows x 130 columns]\n"
     ]
    }
   ],
   "source": [
    "features = train.columns\n",
    "cats = [feat for feat in features if 'cat' in feat]\n",
    "\n",
    "# train, test가 모두 포함되도록 factorize\n",
    "for feat in cats:\n",
    "    train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n",
    "\n",
    "print(train_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10    ...     \\\n",
      "0     0     1     0     1     0     0     0     0     1      0    ...      \n",
      "1     0     1     0     0     0     0     0     0     1      1    ...      \n",
      "2     0     1     0     0     1     0     0     0     1      1    ...      \n",
      "3     1     1     0     1     0     0     0     0     1      0    ...      \n",
      "4     0     1     0     1     0     0     0     0     1      1    ...      \n",
      "\n",
      "      cont5     cont6     cont7    cont8    cont9   cont10    cont11  \\\n",
      "0  0.310061  0.718367  0.335060  0.30260  0.67135  0.83510  0.569745   \n",
      "1  0.885834  0.438917  0.436585  0.60087  0.35127  0.43919  0.338312   \n",
      "2  0.397069  0.289648  0.315545  0.27320  0.26076  0.32446  0.381398   \n",
      "3  0.422268  0.440945  0.391128  0.31796  0.32128  0.44467  0.327915   \n",
      "4  0.704268  0.178193  0.247408  0.24564  0.22089  0.21230  0.204687   \n",
      "\n",
      "     cont12    cont13    cont14  \n",
      "0  0.594646  0.822493  0.714843  \n",
      "1  0.366307  0.611431  0.304496  \n",
      "2  0.373424  0.195709  0.774425  \n",
      "3  0.321570  0.605077  0.602642  \n",
      "4  0.202213  0.246011  0.432606  \n",
      "\n",
      "[5 rows x 130 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_test.head())\n",
    "\n",
    "x_train = np.array(train_test.iloc[:ntrain,:])\n",
    "x_test = np.array(train_test.iloc[ntrain:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, np.log(y_train))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.exp(self.clf.predict(x))\n",
    "\n",
    "\n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=np.log(y_train))\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.exp(self.gbdt.predict(xgb.DMatrix(x)))\n",
    "\n",
    "\n",
    "# out of fold - cross validation\n",
    "def get_oof(clf):\n",
    "    # train\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    train = np.arange(ntrain, dtype=np.int32)\n",
    "        \n",
    "    for i in range(4):\n",
    "        \n",
    "        # 4 fold cross validation\n",
    "        test_index = train[i*int(len(train)*0.25):(i+1)*int(len(train)*0.25)]\n",
    "        train_index = np.setdiff1d(train, test_index)\n",
    "        \n",
    "        # train을 보고 val에 대한 예측을 함\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 7,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "    'nrounds': 350\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "et = SklearnWrapper(clf=ExtraTreesRegressor, seed=SEED, params=et_params)\n",
    "rf = SklearnWrapper(clf=RandomForestRegressor, seed=SEED, params=rf_params)\n",
    "\n",
    "xg_oof_train, xg_oof_test = get_oof(xg)\n",
    "et_oof_train, et_oof_test = get_oof(et)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG-CV: 1146.0922412511977\n",
      "ET-CV: 1238.1211871281023\n",
      "RF-CV: 1289.9668073774656\n"
     ]
    }
   ],
   "source": [
    "print(\"XG-CV: {}\".format(mean_absolute_error(y_train, xg_oof_train)))\n",
    "print(\"ET-CV: {}\".format(mean_absolute_error(y_train, et_oof_train)))\n",
    "print(\"RF-CV: {}\".format(mean_absolute_error(y_train, rf_oof_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 3),(125546, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate((xg_oof_train, et_oof_train, rf_oof_train), axis=1)\n",
    "x_test = np.concatenate((xg_oof_test, et_oof_test, rf_oof_test), axis=1)\n",
    "\n",
    "print(\"{},{}\".format(x_train.shape, x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:1521.34+1514.23\ttest-mae:1521.34+1514.25\n",
      "[10]\ttrain-mae:1520.13+1513.7\ttest-mae:1520.13+1513.73\n",
      "[20]\ttrain-mae:1518.32+1512.51\ttest-mae:1518.32+1512.53\n",
      "[30]\ttrain-mae:1515.59+1510.33\ttest-mae:1515.59+1510.35\n",
      "[40]\ttrain-mae:1511.53+1506.77\ttest-mae:1511.53+1506.79\n",
      "[50]\ttrain-mae:1505.69+1501.39\ttest-mae:1505.69+1501.41\n",
      "[60]\ttrain-mae:1497.57+1493.68\ttest-mae:1497.57+1493.7\n",
      "[70]\ttrain-mae:1486.68+1483.16\ttest-mae:1486.68+1483.19\n",
      "[80]\ttrain-mae:1472.56+1469.38\ttest-mae:1472.56+1469.41\n",
      "[90]\ttrain-mae:1454.84+1451.97\ttest-mae:1454.85+1451.99\n",
      "[100]\ttrain-mae:1433.23+1430.63\ttest-mae:1433.23+1430.66\n",
      "[110]\ttrain-mae:1407.61+1405.25\ttest-mae:1407.61+1405.29\n",
      "[120]\ttrain-mae:1377.98+1375.85\ttest-mae:1377.99+1375.89\n",
      "[130]\ttrain-mae:1344.58+1342.65\ttest-mae:1344.6+1342.7\n",
      "[140]\ttrain-mae:1307.72+1305.97\ttest-mae:1307.74+1306.02\n",
      "[150]\ttrain-mae:1267.78+1266.2\ttest-mae:1267.82+1266.27\n",
      "[160]\ttrain-mae:1225.34+1223.91\ttest-mae:1225.38+1223.98\n",
      "[170]\ttrain-mae:1181.02+1179.72\ttest-mae:1181.08+1179.82\n",
      "[180]\ttrain-mae:1135.53+1134.35\ttest-mae:1135.61+1134.47\n",
      "[190]\ttrain-mae:1089.59+1088.52\ttest-mae:1089.7+1088.66\n",
      "[200]\ttrain-mae:1043.98+1043\ttest-mae:1044.12+1043.18\n",
      "[210]\ttrain-mae:999.351+998.457\ttest-mae:999.549+998.688\n",
      "[220]\ttrain-mae:956.301+955.479\ttest-mae:956.541+955.751\n",
      "[230]\ttrain-mae:915.403+914.643\ttest-mae:915.692+914.965\n",
      "[240]\ttrain-mae:876.971+876.265\ttest-mae:877.322+876.649\n",
      "[250]\ttrain-mae:841.337+840.678\ttest-mae:841.747+841.12\n",
      "[260]\ttrain-mae:808.593+807.973\ttest-mae:809.08+808.491\n",
      "[270]\ttrain-mae:778.958+778.372\ttest-mae:779.518+778.963\n",
      "[280]\ttrain-mae:752.23+751.672\ttest-mae:752.878+752.35\n",
      "[290]\ttrain-mae:728.381+727.847\ttest-mae:729.112+728.608\n",
      "[300]\ttrain-mae:707.252+706.738\ttest-mae:708.063+707.578\n",
      "[310]\ttrain-mae:688.729+688.232\ttest-mae:689.619+689.149\n",
      "[320]\ttrain-mae:672.538+672.055\ttest-mae:673.508+673.05\n",
      "[330]\ttrain-mae:658.405+657.933\ttest-mae:659.451+659.003\n",
      "[340]\ttrain-mae:646.137+645.675\ttest-mae:647.26+646.82\n",
      "[350]\ttrain-mae:635.573+635.119\ttest-mae:636.771+636.338\n",
      "[360]\ttrain-mae:626.477+626.03\ttest-mae:627.732+627.304\n",
      "[370]\ttrain-mae:618.639+618.198\ttest-mae:619.956+619.533\n",
      "[380]\ttrain-mae:611.912+611.475\ttest-mae:613.295+612.876\n",
      "[390]\ttrain-mae:606.197+605.763\ttest-mae:607.622+607.206\n",
      "[400]\ttrain-mae:601.296+600.866\ttest-mae:602.768+602.356\n",
      "[410]\ttrain-mae:597.104+596.676\ttest-mae:598.633+598.223\n",
      "[420]\ttrain-mae:593.561+593.136\ttest-mae:595.137+594.729\n",
      "[430]\ttrain-mae:590.503+590.079\ttest-mae:592.136+591.729\n",
      "[440]\ttrain-mae:587.907+587.485\ttest-mae:589.584+589.178\n",
      "[450]\ttrain-mae:585.687+585.266\ttest-mae:587.404+587\n",
      "[460]\ttrain-mae:583.761+583.341\ttest-mae:585.533+585.129\n",
      "[470]\ttrain-mae:582.116+581.697\ttest-mae:583.936+583.533\n",
      "[480]\ttrain-mae:580.703+580.285\ttest-mae:582.567+582.164\n",
      "[490]\ttrain-mae:579.504+579.087\ttest-mae:581.403+581.001\n",
      "[499]\ttrain-mae:578.582+578.165\ttest-mae:580.509+580.106\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=np.log(y_train))\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'mae',\n",
    "}\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat))\n",
    "\n",
    "res = xgb.cv(xgb_params, dtrain, num_boost_round=500, nfold=4, seed=SEED, stratified=False,\n",
    "             early_stopping_rounds=25, verbose_eval=10, show_stdv=True, feval=xg_eval_mae, maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble-CV: 578.58183925+578.1654189155579\n"
     ]
    }
   ],
   "source": [
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt = xgb.train(xgb_params, dtrain, best_nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(SUBMISSION_FILE)\n",
    "submission.iloc[:, 1] = np.exp(gbdt.predict(dtest))\n",
    "submission.to_csv('xgstacker_starter_v2.sub.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
